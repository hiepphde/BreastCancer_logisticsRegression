# -*- coding: utf-8 -*-
"""BreastCancer_Logicstic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rxmTdOtUQW2ffDZ5KrmaQhki-QhYSEQt

1. Import
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import LabelEncoder

# visualization 
import seaborn as sns
import matplotlib.pyplot as plt
import plotly.express as px

# datasets, classifiers and performance metrics
from sklearn import datasets, metrics, decomposition
from sklearn.metrics import confusion_matrix, RocCurveDisplay
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression

"""2. Data"""

df = pd.read_csv('/content/drive/MyDrive/dataPTDL/BreastCancer.csv')
df = df.drop(['id','Unnamed: 32'], axis=1)

df.head(10)

df.diagnosis.unique()

df.info()

df.describe()



# heatmap 

plt.figure(figsize = (20, 12))

# compute the correlation matrix
corr = df.corr()
# generate a mask for the upper triangle
mask = np.triu(np.ones_like(corr, dtype = bool))

# Generate a custom diverging colormap
cmap = sns.diverging_palette(230, 20, as_cmap=True)

# draw the heatmap with the mask and correct aspect ratio
sns.heatmap(corr, mask = mask, linewidths = 1, cmap=cmap, annot = True, fmt = ".2f")
plt.show()

"""DATA PREPROCESSING"""

corr_matrix = df.corr().abs() 

mask = np.triu(np.ones_like(corr_matrix, dtype = bool))
tri_df = corr_matrix.mask(mask)

to_drop = [x for x in tri_df.columns if any(tri_df[x] > 0.90)]

df = df.drop(to_drop, axis = 1)

print(f"The reduced dataframe has {df.shape[1]} columns.")

Y = df["diagnosis"]
X = df.drop('diagnosis', axis=1)

# Standardize our data to have a mean of 0 and standard deviation of 1
sc = StandardScaler()
X = sc.fit_transform(X)
X.shape

# One-hot encoding our labels
label_Y = LabelEncoder()
Y = label_Y.fit_transform(Y)
Y.shape

rows = df.drop('diagnosis', axis=1).columns
rows.shape

"""PCA"""

n_components = 5
pca = decomposition.PCA(n_components=n_components)
pca.fit(X)
components = pca.transform(X)

columns = []
for i in range(n_components):
  columns.append(f'PC_{i+1}')

feature_importance = pd.DataFrame(pca.components_.T, index=rows, columns=columns)
feature_importance

total_var = pca.explained_variance_ratio_.sum() * 100
total_var

variance_ratios = pd.DataFrame(pca.explained_variance_ratio_.reshape(1,n_components), columns=columns, index=['Explained Variance Ratio'])
variance_ratios

#Heatmap visualization of feature importance
plt.figure(figsize=(15, 8))
sns.heatmap(feature_importance,cmap="YlGnBu")
plt.title('Principal Components correlation with the features')
plt.xlabel('Principal Components')
plt.ylabel('Features')

x_labels = {
   # str(i): f"PC{i+1}"
   # for i in range(n_components)
    str(i): f"PC {i+1} ({var:.1f}%)"
    for i, var in enumerate(pca.explained_variance_ratio_ * 100)
}

y_labels = {
    str(i): f"PC{i+1}"
    for i in range(n_components)
}


fig = px.scatter_matrix(
    components,
    color=df['diagnosis'],
    dimensions=range(5),
    labels=y_labels,
    title=f'Total Explained Variance: {total_var:.2f}%',
)
fig.update_traces(diagonal_visible=False)
fig.show()

"""LOGISTIC REGRESSION"""

X_train, X_test, y_train, y_test = train_test_split(components, Y, test_size=0.2, shuffle=False, random_state=0)

lr = LogisticRegression(random_state=0)
lr.fit(X_train, y_train)

# save the model to disk
import pickle

filename = '/content/drive/MyDrive/Study/Model_Colab/LoR_BreastCancer.sav'
pickle.dump(lr, open(filename, 'wb'))

# load the model from disk
loaded_model = pickle.load(open(filename, 'rb'))
result = loaded_model.score(X_test, y_test)
result

y_pred = lr.predict(X_test)

from sklearn.metrics import accuracy_score

print(accuracy_score(y_test, y_pred))

print(
    f"Classification report for classifier {lr}:\n"
    f"{metrics.classification_report(y_test, y_pred)}\n"
)

cm = confusion_matrix(y_test, y_pred)

ax= plt.subplot()
sns.heatmap(cm, annot=True, fmt='g', ax=ax, cmap='Greens');  #annot=True to annotate cells, ftm='g' to disable scientific notation

# labels, title and ticks
ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); 
ax.set_title('Confusion Matrix'); 
ax.xaxis.set_ticklabels(['Malignant', 'Benign']); ax.yaxis.set_ticklabels(['Malignant', 'Benign']);

RocCurveDisplay.from_estimator(lr, X_test, y_test)
plt.show()

x = X_test[1].reshape(1, -1)
x

pred = lr.predict(x)
pred = [ 1 if y >= 0.5 else 0 for y in pred]
print(pred)

test = [[-0.4, 1, 0.7, -1.7, -2.4]]
test

test_pred = lr.predict(test)
test_pred = [ 1 if y >= 0.5 else 0 for y in test_pred]
print(test_pred)

x = np.array([[int(1), int(1.5), int(5), int(1), int(2)]])
x